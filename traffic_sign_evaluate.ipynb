{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pandas\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "\n",
    "PATH_TO_CKPT = 'exported_graphs/frozen_inference_graph.pb'\n",
    "# data_dir = \"GTSDBxGTSRB\"\n",
    "data_dir = \"GTSDB\"\n",
    "tf_models_dir = \"/home/matech/projects/tf_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"train.record.namestxt\") as f:\n",
    "    file_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pandas.read_csv(os.path.join(data_dir, \"gt.txt\"), sep=\";\", header=None, \n",
    "                         names=(\"file_name\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"label\"))\n",
    "# with open(\"train.record.namestxt\") as f:\n",
    "#     lines = f.read().splitlines()\n",
    "data_to_check = labels#[labels[\"file_name\"].isin(lines)]\n",
    "n_all_images = len(data_to_check[\"file_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pic_shape = (320, 544, 3)\n",
    "def load_image_into_numpy_array(file_names):\n",
    "    xs = []\n",
    "    for file_name in file_names:\n",
    "#         image = imresize(imread(os.path.join(data_dir, file_name.replace(\".ppm\", \".jpg\"))), pic_shape)\n",
    "        image = imresize(imread(os.path.join(data_dir, file_name)), pic_shape)\n",
    "        xs.append(image) # np.append(xs, image_expanded, axis=0)\n",
    "    return np.array(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names = file_list #np.random.choice(data_to_check[\"file_name\"].unique().tolist(), min(800, n_all_images))\n",
    "ys  = []\n",
    "for file_name in file_names:\n",
    "    ys.append((data_to_check[data_to_check[\"file_name\"] == file_name][\"label\"] + 1).astype(int).unique().tolist())\n",
    "# xs = load_image_into_numpy_array(data_to_check[\"file_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8407177925109863\n",
      "0.14804625511169434\n",
      "0.1598970890045166\n",
      "0.14768433570861816\n",
      "0.16559529304504395\n",
      "0.15615129470825195\n",
      "0.15861845016479492\n",
      "0.15379047393798828\n",
      "0.15496158599853516\n",
      "0.14969778060913086\n",
      "0.17400431632995605\n",
      "0.14981961250305176\n",
      "0.1685163974761963\n",
      "0.14534306526184082\n",
      "0.17475128173828125\n",
      "0.15217351913452148\n",
      "0.1690206527709961\n",
      "0.1482248306274414\n",
      "0.15779495239257812\n",
      "0.1446840763092041\n",
      "0.16623616218566895\n",
      "0.14583945274353027\n",
      "0.14745044708251953\n",
      "0.14813852310180664\n",
      "0.14474129676818848\n",
      "0.15394330024719238\n",
      "0.17284107208251953\n",
      "0.14422369003295898\n",
      "0.14600062370300293\n",
      "0.17301082611083984\n",
      "0.17167186737060547\n",
      "0.1602494716644287\n",
      "0.15847063064575195\n",
      "0.17820978164672852\n",
      "0.14562392234802246\n",
      "0.14563441276550293\n",
      "0.16998291015625\n",
      "0.14786934852600098\n",
      "0.17051076889038086\n",
      "0.14806342124938965\n",
      "0.14718198776245117\n",
      "0.15010690689086914\n",
      "0.15691852569580078\n",
      "0.17043137550354004\n",
      "0.15372133255004883\n",
      "0.14795255661010742\n",
      "0.15153098106384277\n",
      "0.15254902839660645\n",
      "0.14708352088928223\n",
      "0.1485447883605957\n",
      "0.14642548561096191\n",
      "0.1470656394958496\n",
      "0.17369461059570312\n",
      "0.17098760604858398\n",
      "0.14548563957214355\n",
      "0.14729571342468262\n",
      "0.1663808822631836\n",
      "0.14536380767822266\n",
      "0.1464376449584961\n",
      "0.14601898193359375\n",
      "0.14868545532226562\n",
      "0.14507484436035156\n",
      "0.16053199768066406\n",
      "0.14676308631896973\n",
      "0.16147923469543457\n",
      "0.14529895782470703\n",
      "0.14713168144226074\n",
      "0.15073585510253906\n",
      "0.1462869644165039\n",
      "0.14613580703735352\n",
      "0.14885926246643066\n",
      "0.14746809005737305\n",
      "0.15759825706481934\n",
      "0.14908337593078613\n",
      "0.1561269760131836\n",
      "0.15615606307983398\n",
      "0.14685416221618652\n",
      "0.14356493949890137\n",
      "0.14457917213439941\n",
      "0.14830684661865234\n",
      "0.1627638339996338\n",
      "0.14883708953857422\n",
      "0.15126967430114746\n",
      "0.14918160438537598\n",
      "0.14552736282348633\n",
      "0.14597773551940918\n",
      "0.17369771003723145\n",
      "0.16480278968811035\n",
      "0.16544699668884277\n",
      "0.17023611068725586\n",
      "0.1671314239501953\n",
      "0.1657247543334961\n",
      "0.14700698852539062\n",
      "0.14827442169189453\n",
      "0.1703813076019287\n",
      "0.16618800163269043\n",
      "0.1710362434387207\n",
      "0.15140867233276367\n",
      "0.1454484462738037\n",
      "0.15546298027038574\n",
      "0.15236711502075195\n",
      "0.14841413497924805\n",
      "0.14730048179626465\n",
      "0.15750527381896973\n",
      "0.15442919731140137\n",
      "0.15781903266906738\n",
      "0.1685621738433838\n",
      "0.17215514183044434\n",
      "0.16883420944213867\n",
      "0.1595907211303711\n",
      "0.15314888954162598\n",
      "0.14848017692565918\n",
      "0.15338611602783203\n",
      "0.12519621849060059\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 6\n",
    "n_images = len(ys)\n",
    "accs = pandas.DataFrame(columns=[\"acc\"], index=data_to_check[\"file_name\"].unique())\n",
    "results = {}\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        \n",
    "        scores = []\n",
    "        classes = []\n",
    "        for i in range(math.ceil(n_images/batch_size)):\n",
    "#             print(i/math.ceil(n_images/batch_size))\n",
    "            start = i*batch_size\n",
    "            batch_file_names = file_names[start:min(n_images,start+batch_size)]\n",
    "            xs = load_image_into_numpy_array(batch_file_names)\n",
    "            start = time.time()\n",
    "            (ss, cs) = sess.run([detection_scores, detection_classes], \n",
    "                              feed_dict={image_tensor: xs})\n",
    "            end = time.time()\n",
    "            print(end-start)\n",
    "            for s, c in zip(ss, cs):\n",
    "                scores.append(s)\n",
    "                classes.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accs = []\n",
    "for i in range(n_images):\n",
    "    score = scores[i]\n",
    "    classe = classes[i]\n",
    "    res = pandas.DataFrame(data={\"score\": score, \"class\": classe})\n",
    "    predicted_labels = res[res[\"score\"] > 0.25][\"class\"].astype(int)\n",
    "    gt_labels = pandas.Series(ys[i])\n",
    "    results[file_name] = (predicted_labels, gt_labels, score, classe)\n",
    "    correct_pred_labels = predicted_labels[predicted_labels.isin(gt_labels)].unique()\n",
    "    all_labels_involved = predicted_labels.append(gt_labels).unique()\n",
    "    if len(all_labels_involved) != 0:\n",
    "        acc = len(correct_pred_labels)/len(all_labels_involved)\n",
    "        accs.append(acc)\n",
    "    else:\n",
    "        print(\"No label:\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.476891166423\n",
      "0.38799414348462663\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accs))\n",
    "perfects = list(x for x in accs if x > 0.99)\n",
    "print(len(perfects)/len(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
